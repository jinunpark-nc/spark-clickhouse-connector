{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview Spark ClickHouse Connector is a high performance connector build on top of Spark DataSource V2 and ClickHouse gRPC protocol. Requirements Basic knowledge of Apache Spark and ClickHouse . An available ClickHouse single node or cluster, and ClickHouse version should at least v21.1.2.15-stable , because Spark communicate with ClickHouse through the gRPC protocol. An available Spark cluster, and Spark version should be 3.2.x, because we need the interfaces of Spark DataSource V2 added in 3.2.0. Make sure your network policy satisfy the requirements, both driver and executor of Spark need to access ClickHouse gRPC port. If you are using it to access ClickHouse cluster, ensure the connectivity between driver and executor of Spark and each node of ClickHouse cluster. Notes Integration tests based on Java 8, Scala 2.12, Spark v3.2.0 and ClickHouse v21.8.10.19-lts, with both single ClickHouse instance and cluster mode.","title":"Home"},{"location":"#overview","text":"Spark ClickHouse Connector is a high performance connector build on top of Spark DataSource V2 and ClickHouse gRPC protocol.","title":"Overview"},{"location":"#requirements","text":"Basic knowledge of Apache Spark and ClickHouse . An available ClickHouse single node or cluster, and ClickHouse version should at least v21.1.2.15-stable , because Spark communicate with ClickHouse through the gRPC protocol. An available Spark cluster, and Spark version should be 3.2.x, because we need the interfaces of Spark DataSource V2 added in 3.2.0. Make sure your network policy satisfy the requirements, both driver and executor of Spark need to access ClickHouse gRPC port. If you are using it to access ClickHouse cluster, ensure the connectivity between driver and executor of Spark and each node of ClickHouse cluster.","title":"Requirements"},{"location":"#notes","text":"Integration tests based on Java 8, Scala 2.12, Spark v3.2.0 and ClickHouse v21.8.10.19-lts, with both single ClickHouse instance and cluster mode.","title":"Notes"},{"location":"best_practices/","text":"TODO","title":"Index"},{"location":"best_practices/#todo","text":"","title":"TODO"},{"location":"best_practices/01_deployment/","text":"Deployment Jar Put clickhouse-spark-32-runtime_2.12-{version}.jar into $SPARK_HOME/jars/ , then you don't need to bundle the jar into your Spark application, and --jar is not required when using spark-shell or spark-sql (again, for SQL-only use cases, Apache Kyuubi(Incubating) is recommended for Production). Configuration Persist catalog configurations into SPARK_HOME/conf/spark-defaults.conf , then --conf s are not required when using spark-shell or spark-sql . spark.sql.catalog.ck_01=xenon.clickhouse.ClickHouseCatalog spark.sql.catalog.ck_01.host=10.0.0.1 spark.sql.catalog.ck_01.grpc_port=9100 spark.sql.catalog.ck_01.user=app spark.sql.catalog.ck_01.password=pwd spark.sql.catalog.ck_01.database=default spark.sql.catalog.ck_02=xenon.clickhouse.ClickHouseCatalog spark.sql.catalog.ck_02.host=10.0.0.2 spark.sql.catalog.ck_02.grpc_port=9100 spark.sql.catalog.ck_02.user=app spark.sql.catalog.ck_02.password=pwd spark.sql.catalog.ck_02.database=default","title":"Deployment"},{"location":"best_practices/01_deployment/#deployment","text":"","title":"Deployment"},{"location":"best_practices/01_deployment/#jar","text":"Put clickhouse-spark-32-runtime_2.12-{version}.jar into $SPARK_HOME/jars/ , then you don't need to bundle the jar into your Spark application, and --jar is not required when using spark-shell or spark-sql (again, for SQL-only use cases, Apache Kyuubi(Incubating) is recommended for Production).","title":"Jar"},{"location":"best_practices/01_deployment/#configuration","text":"Persist catalog configurations into SPARK_HOME/conf/spark-defaults.conf , then --conf s are not required when using spark-shell or spark-sql . spark.sql.catalog.ck_01=xenon.clickhouse.ClickHouseCatalog spark.sql.catalog.ck_01.host=10.0.0.1 spark.sql.catalog.ck_01.grpc_port=9100 spark.sql.catalog.ck_01.user=app spark.sql.catalog.ck_01.password=pwd spark.sql.catalog.ck_01.database=default spark.sql.catalog.ck_02=xenon.clickhouse.ClickHouseCatalog spark.sql.catalog.ck_02.host=10.0.0.2 spark.sql.catalog.ck_02.grpc_port=9100 spark.sql.catalog.ck_02.user=app spark.sql.catalog.ck_02.password=pwd spark.sql.catalog.ck_02.database=default","title":"Configuration"},{"location":"configurations/","text":"Configurations TODO Overwrite SQL Configurations Your can overwrite ClickHouse SQL Configurations by editing $SPARK_HOME/conf/spark-defaults.conf . spark.clickhouse.write.batchSize 10000 spark.clickhouse.write.maxRetry 2","title":"Index"},{"location":"configurations/#configurations","text":"","title":"Configurations"},{"location":"configurations/#todo","text":"","title":"TODO"},{"location":"configurations/#overwrite-sql-configurations","text":"Your can overwrite ClickHouse SQL Configurations by editing $SPARK_HOME/conf/spark-defaults.conf . spark.clickhouse.write.batchSize 10000 spark.clickhouse.write.maxRetry 2","title":"Overwrite SQL Configurations"},{"location":"configurations/01_catalog_configurations/","text":"Catalog Configurations Single Instance Suppose you have one ClickHouse instance which installed on 10.0.0.1 and expose gRPC at port 9100 . Edit $SPARK_HOME/conf/spark-defaults.conf . spark.sql.catalog.clickhouse xenon.clickhouse.ClickHouseCatalog spark.sql.catalog.clickhouse.host 10.0.0.1 spark.sql.catalog.clickhouse.grpc_port 9100 spark.sql.catalog.clickhouse.user default spark.sql.catalog.clickhouse.password spark.sql.catalog.clickhouse.database default Then you can access ClickHouse table <ck_db>.<ck_table> from Spark SQL by using clickhouse.<ck_db>.<ck_table> . Cluster For ClickHouse cluster, give an unique catalog name for each instances. Suppose you have two ClickHouse instances, one installed on 10.0.0.1 and expose gRPC at port 9100 named clickhouse-1, and another installed on 10.0.0.2 and expose gRPC at port 9100 named clickhouse-2. Edit $SPARK_HOME/conf/spark-defaults.conf . spark.sql.catalog.clickhouse-1 xenon.clickhouse.ClickHouseCatalog spark.sql.catalog.clickhouse-1.host 10.0.0.1 spark.sql.catalog.clickhouse-1.grpc_port 9100 spark.sql.catalog.clickhouse-1.user default spark.sql.catalog.clickhouse-1.password spark.sql.catalog.clickhouse-1.database default spark.sql.catalog.clickhouse-2 xenon.clickhouse.ClickHouseCatalog spark.sql.catalog.clickhouse-2.host 10.0.0.2 spark.sql.catalog.clickhouse-2.grpc_port 9100 spark.sql.catalog.clickhouse-2.user default spark.sql.catalog.clickhouse-2.password spark.sql.catalog.clickhouse-2.database default Then you can access clickhouse-1 table <ck_db>.<ck_table> from Spark SQL by using clickhouse-1.<ck_db>.<ck_table> , and access clickhouse-2 table <ck_db>.<ck_table> by using clickhouse-2.<ck_db>.<ck_table> .","title":"Catalog Configurations"},{"location":"configurations/01_catalog_configurations/#catalog-configurations","text":"","title":"Catalog Configurations"},{"location":"configurations/01_catalog_configurations/#single-instance","text":"Suppose you have one ClickHouse instance which installed on 10.0.0.1 and expose gRPC at port 9100 . Edit $SPARK_HOME/conf/spark-defaults.conf . spark.sql.catalog.clickhouse xenon.clickhouse.ClickHouseCatalog spark.sql.catalog.clickhouse.host 10.0.0.1 spark.sql.catalog.clickhouse.grpc_port 9100 spark.sql.catalog.clickhouse.user default spark.sql.catalog.clickhouse.password spark.sql.catalog.clickhouse.database default Then you can access ClickHouse table <ck_db>.<ck_table> from Spark SQL by using clickhouse.<ck_db>.<ck_table> .","title":"Single Instance"},{"location":"configurations/01_catalog_configurations/#cluster","text":"For ClickHouse cluster, give an unique catalog name for each instances. Suppose you have two ClickHouse instances, one installed on 10.0.0.1 and expose gRPC at port 9100 named clickhouse-1, and another installed on 10.0.0.2 and expose gRPC at port 9100 named clickhouse-2. Edit $SPARK_HOME/conf/spark-defaults.conf . spark.sql.catalog.clickhouse-1 xenon.clickhouse.ClickHouseCatalog spark.sql.catalog.clickhouse-1.host 10.0.0.1 spark.sql.catalog.clickhouse-1.grpc_port 9100 spark.sql.catalog.clickhouse-1.user default spark.sql.catalog.clickhouse-1.password spark.sql.catalog.clickhouse-1.database default spark.sql.catalog.clickhouse-2 xenon.clickhouse.ClickHouseCatalog spark.sql.catalog.clickhouse-2.host 10.0.0.2 spark.sql.catalog.clickhouse-2.grpc_port 9100 spark.sql.catalog.clickhouse-2.user default spark.sql.catalog.clickhouse-2.password spark.sql.catalog.clickhouse-2.database default Then you can access clickhouse-1 table <ck_db>.<ck_table> from Spark SQL by using clickhouse-1.<ck_db>.<ck_table> , and access clickhouse-2 table <ck_db>.<ck_table> by using clickhouse-2.<ck_db>.<ck_table> .","title":"Cluster"},{"location":"configurations/02_sql_configurations/","text":"SQL Configurations Since 1.0.0 - spark.clickhouse.write.batchSize Default Value: 10000 Description: The number of records per batch on writing to ClickHouse. Since 1.0.0 - spark.clickhouse.write.maxRetry Default Value: 3 Description: The maximum number of write we will retry for a single batch write failed with retryable codes. Since 1.0.0 - spark.clickhouse.write.retryInterval Default Value: 10 Description: The interval in seconds between write retry. Since 1.0.0 - spark.clickhouse.write.retryableErrorCodes Default Value: 241 Description: The retryable error codes returned by ClickHouse server when write failing. Since 1.0.0 - spark.clickhouse.write.repartitionNum Default Value: 0 Description: Repartition data to meet the distributions of ClickHouse table is required before writing, use this conf to specific the repartition number, value less than 1 mean no requirement. Since 1.0.0 - spark.clickhouse.write.distributed.useClusterNodes Default Value: true Description: Write to all nodes of cluster when writing Distributed table. Since 1.0.0 - spark.clickhouse.read.distributed.useClusterNodes Default Value: false Description: Read from all nodes of cluster when reading Distributed table. Since 1.0.0 - spark.clickhouse.write.distributed.convertLocal Default Value: false Description: When writing Distributed table, write local table instead of itself. If true , ignore write.distributed.useClusterNodes . Since 1.0.0 - spark.clickhouse.read.distributed.convertLocal Default Value: true Description: When reading Distributed table, read local table instead of itself. If true , ignore read.distributed.useClusterNodes . Since 1.0.0 - spark.clickhouse.truncate.distributed.convertLocal Default Value: true Description: When truncate Distributed table, truncate local table instead of itself.","title":"SQL Configurations"},{"location":"configurations/02_sql_configurations/#sql-configurations","text":"Since 1.0.0 - spark.clickhouse.write.batchSize Default Value: 10000 Description: The number of records per batch on writing to ClickHouse. Since 1.0.0 - spark.clickhouse.write.maxRetry Default Value: 3 Description: The maximum number of write we will retry for a single batch write failed with retryable codes. Since 1.0.0 - spark.clickhouse.write.retryInterval Default Value: 10 Description: The interval in seconds between write retry. Since 1.0.0 - spark.clickhouse.write.retryableErrorCodes Default Value: 241 Description: The retryable error codes returned by ClickHouse server when write failing. Since 1.0.0 - spark.clickhouse.write.repartitionNum Default Value: 0 Description: Repartition data to meet the distributions of ClickHouse table is required before writing, use this conf to specific the repartition number, value less than 1 mean no requirement. Since 1.0.0 - spark.clickhouse.write.distributed.useClusterNodes Default Value: true Description: Write to all nodes of cluster when writing Distributed table. Since 1.0.0 - spark.clickhouse.read.distributed.useClusterNodes Default Value: false Description: Read from all nodes of cluster when reading Distributed table. Since 1.0.0 - spark.clickhouse.write.distributed.convertLocal Default Value: false Description: When writing Distributed table, write local table instead of itself. If true , ignore write.distributed.useClusterNodes . Since 1.0.0 - spark.clickhouse.read.distributed.convertLocal Default Value: true Description: When reading Distributed table, read local table instead of itself. If true , ignore read.distributed.useClusterNodes . Since 1.0.0 - spark.clickhouse.truncate.distributed.convertLocal Default Value: true Description: When truncate Distributed table, truncate local table instead of itself.","title":"SQL Configurations"},{"location":"developers/","text":"TODO","title":"Index"},{"location":"developers/#todo","text":"","title":"TODO"},{"location":"internals/","text":"TODO","title":"Index"},{"location":"internals/#todo","text":"","title":"TODO"},{"location":"quick_start/01_preparation/","text":"Preparation The project has no available binary release now, you must build from source code before using. Also, it has not been published to Maven Central, you need to build and publish to private repository if you want import it by using Gradle or Maven to your project. Build Jar from Source Code Check out source code from GitHub. git checkout https://github.com/housepower/spark-clickhouse-connector.git Build. ./gradlew clean build -x test Go to clickhouse-spark-32-runtime/build/libs/ to find the output jar clickhouse-spark-32-runtime_2.12-${version}.jar . Publish to Private Repository Configure Gradle in ~/.gradle/gradle.properties . mavenUser=xxx mavenPassword=xxx mavenReleasesRepo=xxx mavenSnapshotsRepo=xxx Versions. Use content of ./version.txt if the file exists, otherwise fallback to {year}.{month}.{date}[-SNAPSHOT] . Publish Snapshots. ./gradlew publish Publish Release. ./gradlew -Prelease publish Import as Dependency For Gradle. dependencies { implementation(\"com.github.housepower:clickhouse-spark-32-runtime_2.12:${version}\") } For Maven. <dependency> <groupId>com.github.housepower</groupId> <artifactId>clickhouse-spark-32-runtime_2.12</artifactId> <version>${version}</version> </dependency>","title":"Preparation"},{"location":"quick_start/01_preparation/#preparation","text":"The project has no available binary release now, you must build from source code before using. Also, it has not been published to Maven Central, you need to build and publish to private repository if you want import it by using Gradle or Maven to your project.","title":"Preparation"},{"location":"quick_start/01_preparation/#build-jar-from-source-code","text":"Check out source code from GitHub. git checkout https://github.com/housepower/spark-clickhouse-connector.git Build. ./gradlew clean build -x test Go to clickhouse-spark-32-runtime/build/libs/ to find the output jar clickhouse-spark-32-runtime_2.12-${version}.jar .","title":"Build Jar from Source Code"},{"location":"quick_start/01_preparation/#publish-to-private-repository","text":"Configure Gradle in ~/.gradle/gradle.properties . mavenUser=xxx mavenPassword=xxx mavenReleasesRepo=xxx mavenSnapshotsRepo=xxx Versions. Use content of ./version.txt if the file exists, otherwise fallback to {year}.{month}.{date}[-SNAPSHOT] . Publish Snapshots. ./gradlew publish Publish Release. ./gradlew -Prelease publish","title":"Publish to Private Repository"},{"location":"quick_start/01_preparation/#import-as-dependency","text":"For Gradle. dependencies { implementation(\"com.github.housepower:clickhouse-spark-32-runtime_2.12:${version}\") } For Maven. <dependency> <groupId>com.github.housepower</groupId> <artifactId>clickhouse-spark-32-runtime_2.12</artifactId> <version>${version}</version> </dependency>","title":"Import as Dependency"},{"location":"quick_start/02_play_with_spark_sql/","text":"Play with Spark SQL Note: For SQL-only use cases, Apache Kyuubi(Incubating) is recommended for Production. Launch Spark SQL CLI $SPARK_HOME/bin/spark-sql \\ --conf spark.sql.catalog.clickhouse=xenon.clickhouse.ClickHouseCatalog \\ --conf spark.sql.catalog.clickhouse.host=${CLICKHOUSE_HOST:-127.0.0.1} \\ --conf spark.sql.catalog.clickhouse.grpc_port=${CLICKHOUSE_GRPC_PORT:-9100} \\ --conf spark.sql.catalog.clickhouse.user=${CLICKHOUSE_USER:-default} \\ --conf spark.sql.catalog.clickhouse.password=${CLICKHOUSE_PASSWORD:-} \\ --conf spark.sql.catalog.clickhouse.database=default \\ --jars /path/clickhouse-spark-32-runtime_2.12-{version}.jar If you published the jar to private Nexus, the following argument --jars /path/clickhouse-spark-32-runtime_2.12-{version}.jar can be replaced by --repositories https://{private-nexus-repo} \\ --packages com.github.housepower:clickhouse-spark-32-runtime_2.12:{version} to avoid copying jar to your Spark client node. Operations Basic operations, e.g. create database, create table, write table, read table, etc. spark-sql> use clickhouse; Time taken: 0.016 seconds spark-sql> create database if not exists test_db; Time taken: 0.022 seconds spark-sql> show databases; default system test_db Time taken: 0.289 seconds, Fetched 3 row(s) spark-sql> CREATE TABLE test_db.tbl_sql ( > create_time TIMESTAMP NOT NULL, > m INT NOT NULL COMMENT 'part key', > id BIGINT NOT NULL COMMENT 'sort key', > value STRING > ) USING ClickHouse > PARTITIONED BY (m) > TBLPROPERTIES ( > engine = 'MergeTree()', > order_by = '(id)', > settings.index_granularity = 8192 > ); Time taken: 0.242 seconds spark-sql> insert into test_db.tbl_sql values > (timestamp'2021-01-01 10:10:10', 1, 1L, '1'), > (timestamp'2022-02-02 10:10:10', 2, 2L, '2') > as tabl(create_time, m, id, value); Time taken: 0.276 seconds spark-sql> select * from test_db.tbl_sql; 2021-01-01 10:10:10 1 1 1 2022-02-02 10:10:10 2 2 2 Time taken: 0.116 seconds, Fetched 2 row(s) spark-sql> insert into test_db.tbl_sql select * from test_db.tbl_sql; Time taken: 1.028 seconds spark-sql> insert into test_db.tbl_sql select * from test_db.tbl_sql; Time taken: 0.462 seconds spark-sql> select count(*) from test_db.tbl_sql; 6 Time taken: 1.421 seconds, Fetched 1 row(s) spark-sql> select * from test_db.tbl_sql; 2021-01-01 10:10:10 1 1 1 2021-01-01 10:10:10 1 1 1 2021-01-01 10:10:10 1 1 1 2022-02-02 10:10:10 2 2 2 2022-02-02 10:10:10 2 2 2 2022-02-02 10:10:10 2 2 2 Time taken: 0.123 seconds, Fetched 6 row(s)","title":"Play with Spark SQL"},{"location":"quick_start/02_play_with_spark_sql/#play-with-spark-sql","text":"Note: For SQL-only use cases, Apache Kyuubi(Incubating) is recommended for Production.","title":"Play with Spark SQL"},{"location":"quick_start/02_play_with_spark_sql/#launch-spark-sql-cli","text":"$SPARK_HOME/bin/spark-sql \\ --conf spark.sql.catalog.clickhouse=xenon.clickhouse.ClickHouseCatalog \\ --conf spark.sql.catalog.clickhouse.host=${CLICKHOUSE_HOST:-127.0.0.1} \\ --conf spark.sql.catalog.clickhouse.grpc_port=${CLICKHOUSE_GRPC_PORT:-9100} \\ --conf spark.sql.catalog.clickhouse.user=${CLICKHOUSE_USER:-default} \\ --conf spark.sql.catalog.clickhouse.password=${CLICKHOUSE_PASSWORD:-} \\ --conf spark.sql.catalog.clickhouse.database=default \\ --jars /path/clickhouse-spark-32-runtime_2.12-{version}.jar If you published the jar to private Nexus, the following argument --jars /path/clickhouse-spark-32-runtime_2.12-{version}.jar can be replaced by --repositories https://{private-nexus-repo} \\ --packages com.github.housepower:clickhouse-spark-32-runtime_2.12:{version} to avoid copying jar to your Spark client node.","title":"Launch Spark SQL CLI"},{"location":"quick_start/02_play_with_spark_sql/#operations","text":"Basic operations, e.g. create database, create table, write table, read table, etc. spark-sql> use clickhouse; Time taken: 0.016 seconds spark-sql> create database if not exists test_db; Time taken: 0.022 seconds spark-sql> show databases; default system test_db Time taken: 0.289 seconds, Fetched 3 row(s) spark-sql> CREATE TABLE test_db.tbl_sql ( > create_time TIMESTAMP NOT NULL, > m INT NOT NULL COMMENT 'part key', > id BIGINT NOT NULL COMMENT 'sort key', > value STRING > ) USING ClickHouse > PARTITIONED BY (m) > TBLPROPERTIES ( > engine = 'MergeTree()', > order_by = '(id)', > settings.index_granularity = 8192 > ); Time taken: 0.242 seconds spark-sql> insert into test_db.tbl_sql values > (timestamp'2021-01-01 10:10:10', 1, 1L, '1'), > (timestamp'2022-02-02 10:10:10', 2, 2L, '2') > as tabl(create_time, m, id, value); Time taken: 0.276 seconds spark-sql> select * from test_db.tbl_sql; 2021-01-01 10:10:10 1 1 1 2022-02-02 10:10:10 2 2 2 Time taken: 0.116 seconds, Fetched 2 row(s) spark-sql> insert into test_db.tbl_sql select * from test_db.tbl_sql; Time taken: 1.028 seconds spark-sql> insert into test_db.tbl_sql select * from test_db.tbl_sql; Time taken: 0.462 seconds spark-sql> select count(*) from test_db.tbl_sql; 6 Time taken: 1.421 seconds, Fetched 1 row(s) spark-sql> select * from test_db.tbl_sql; 2021-01-01 10:10:10 1 1 1 2021-01-01 10:10:10 1 1 1 2021-01-01 10:10:10 1 1 1 2022-02-02 10:10:10 2 2 2 2022-02-02 10:10:10 2 2 2 2022-02-02 10:10:10 2 2 2 Time taken: 0.123 seconds, Fetched 6 row(s)","title":"Operations"},{"location":"quick_start/03_play_with_spark_shell/","text":"Play with Spark Shell Launch Spark Shell $SPARK_HOME/bin/spark-shell \\ --conf spark.sql.catalog.clickhouse=xenon.clickhouse.ClickHouseCatalog \\ --conf spark.sql.catalog.clickhouse.host=${CLICKHOUSE_HOST:-127.0.0.1} \\ --conf spark.sql.catalog.clickhouse.grpc_port=${CLICKHOUSE_GRPC_PORT:-9100} \\ --conf spark.sql.catalog.clickhouse.user=${CLICKHOUSE_USER:-default} \\ --conf spark.sql.catalog.clickhouse.password=${CLICKHOUSE_PASSWORD:-} \\ --conf spark.sql.catalog.clickhouse.database=default \\ --jars /path/clickhouse-spark-32-runtime_2.12-{version}.jar If you published the jar to private Nexus, the following argument --jars /path/clickhouse-spark-32-runtime_2.12-{version}.jar can be replaced by --repositories https://{private-nexus-repo} \\ --packages com.github.housepower:clickhouse-spark-32-runtime_2.12:{version} to avoid copying jar to your Spark client node. Operations Basic operations, e.g. create database, create table, write table, read table, etc. scala> spark.sql(\"use clickhouse\") res0: org.apache.spark.sql.DataFrame = [] scala> spark.sql(\"create database test_db\") res1: org.apache.spark.sql.DataFrame = [] scala> spark.sql(\"show databases\").show +---------+ |namespace| +---------+ | default| | system| | test_db| +---------+ scala> spark.sql(\"\"\" | CREATE TABLE test_db.tbl ( | create_time TIMESTAMP NOT NULL, | m INT NOT NULL COMMENT 'part key', | id BIGINT NOT NULL COMMENT 'sort key', | value STRING | ) USING ClickHouse | PARTITIONED BY (m) | TBLPROPERTIES ( | engine = 'MergeTree()', | order_by = '(id)', | settings.index_granularity = 8192 | ) | \"\"\") res2: org.apache.spark.sql.DataFrame = [] scala> :paste // Entering paste mode (ctrl-D to finish) spark.createDataFrame(Seq( (\"2021-01-01 10:10:10\", 1L, \"1\"), (\"2022-02-02 10:10:10\", 2L, \"2\") )).toDF(\"create_time\", \"id\", \"value\") .withColumn(\"create_time\", to_timestamp($\"create_time\")) .withColumn(\"m\", month($\"create_time\")) .select($\"create_time\", $\"m\", $\"id\", $\"value\") .writeTo(\"test_db.tbl\") .append // Exiting paste mode, now interpreting. scala> spark.table(\"test_db.tbl\").show +-------------------+---+---+-----+ | create_time| m| id|value| +-------------------+---+---+-----+ |2021-01-01 10:10:10| 1| 1| 1| |2022-02-02 10:10:10| 2| 2| 2| +-------------------+---+---+-----+","title":"Play with Spark Shell"},{"location":"quick_start/03_play_with_spark_shell/#play-with-spark-shell","text":"","title":"Play with Spark Shell"},{"location":"quick_start/03_play_with_spark_shell/#launch-spark-shell","text":"$SPARK_HOME/bin/spark-shell \\ --conf spark.sql.catalog.clickhouse=xenon.clickhouse.ClickHouseCatalog \\ --conf spark.sql.catalog.clickhouse.host=${CLICKHOUSE_HOST:-127.0.0.1} \\ --conf spark.sql.catalog.clickhouse.grpc_port=${CLICKHOUSE_GRPC_PORT:-9100} \\ --conf spark.sql.catalog.clickhouse.user=${CLICKHOUSE_USER:-default} \\ --conf spark.sql.catalog.clickhouse.password=${CLICKHOUSE_PASSWORD:-} \\ --conf spark.sql.catalog.clickhouse.database=default \\ --jars /path/clickhouse-spark-32-runtime_2.12-{version}.jar If you published the jar to private Nexus, the following argument --jars /path/clickhouse-spark-32-runtime_2.12-{version}.jar can be replaced by --repositories https://{private-nexus-repo} \\ --packages com.github.housepower:clickhouse-spark-32-runtime_2.12:{version} to avoid copying jar to your Spark client node.","title":"Launch Spark Shell"},{"location":"quick_start/03_play_with_spark_shell/#operations","text":"Basic operations, e.g. create database, create table, write table, read table, etc. scala> spark.sql(\"use clickhouse\") res0: org.apache.spark.sql.DataFrame = [] scala> spark.sql(\"create database test_db\") res1: org.apache.spark.sql.DataFrame = [] scala> spark.sql(\"show databases\").show +---------+ |namespace| +---------+ | default| | system| | test_db| +---------+ scala> spark.sql(\"\"\" | CREATE TABLE test_db.tbl ( | create_time TIMESTAMP NOT NULL, | m INT NOT NULL COMMENT 'part key', | id BIGINT NOT NULL COMMENT 'sort key', | value STRING | ) USING ClickHouse | PARTITIONED BY (m) | TBLPROPERTIES ( | engine = 'MergeTree()', | order_by = '(id)', | settings.index_granularity = 8192 | ) | \"\"\") res2: org.apache.spark.sql.DataFrame = [] scala> :paste // Entering paste mode (ctrl-D to finish) spark.createDataFrame(Seq( (\"2021-01-01 10:10:10\", 1L, \"1\"), (\"2022-02-02 10:10:10\", 2L, \"2\") )).toDF(\"create_time\", \"id\", \"value\") .withColumn(\"create_time\", to_timestamp($\"create_time\")) .withColumn(\"m\", month($\"create_time\")) .select($\"create_time\", $\"m\", $\"id\", $\"value\") .writeTo(\"test_db.tbl\") .append // Exiting paste mode, now interpreting. scala> spark.table(\"test_db.tbl\").show +-------------------+---+---+-----+ | create_time| m| id|value| +-------------------+---+---+-----+ |2021-01-01 10:10:10| 1| 1| 1| |2022-02-02 10:10:10| 2| 2| 2| +-------------------+---+---+-----+","title":"Operations"}]}